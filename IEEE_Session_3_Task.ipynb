{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostaf7583/IEEE-tasks/blob/task3/IEEE_Session_3_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 3 Task <img src=\"https://i.imgur.com/9y2NKWY.png\" align=\"right\" width=80/>\n",
        "\n",
        "This task focuses on:\n",
        "\n",
        "\n",
        "\n",
        "*   End-to-end machine learning on a classification problem\n",
        "*   Training multiclass classification models\n",
        "*   Making sense of confusion matrices and metrics to assess model performances\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NFYD5Slt-FAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reminder: End-to-end Machien Learning steps are to \n",
        "\n",
        "\n",
        "\n",
        "1.   Download the data\n",
        "2.   Understand and Clean the Data\n",
        "3.   Preprocess and Feature Engineer the Data\n",
        "4.   Train a model using the data\n",
        "5.   Measure the model's performance using cross validation\n",
        "6.   Do hyperparameter tuning on the model and/or try different models\n",
        "7.   Use the final selected model to make predictions on the test set\n",
        "\n"
      ],
      "metadata": {
        "id": "MnZz-TiLUAzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this task, we won't be using pipelines!\n",
        "\n",
        "This is for a few reasons:\n",
        "\n",
        "\n",
        "\n",
        "*   There are often a few different ways to accomplish something in data science\n",
        "you don't need to know all of them but you also shouldn't only have one tool in \n",
        "your toolbox \n",
        "*   Pipelines hide some of the underlying complexity of preprocessing and \n",
        "building models, this is great if you understand how everything works and just\n",
        "want to deploy to production, but when you're learning it's often a good idea\n",
        "to tinker with the tools you're using and try to get a better understanding of\n",
        "how they work. \n",
        "\n"
      ],
      "metadata": {
        "id": "wRoAceVPVDLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> In this task we'll train and select a multiclass classification model to predict whether a car's price is within one of five price categories.<h2>"
      ],
      "metadata": {
        "id": "WKNx---Iue6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First, let's load the data"
      ],
      "metadata": {
        "id": "uxNciqYTUVaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1o2-1X1tRMj5lPS5NOVAfE7gkGqIXC35q\n",
        "!gdown 1-aMbeDwChOmgRC2ICAM0X3Nvx8PeuyyC\n",
        "!gdown 1t1HHi_LeAEW5rXkaoTMHYIo2KuJvgLRI"
      ],
      "metadata": {
        "id": "uLmCqXyA-rTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: We'll drop the id column from the test set since the sample submission file has the same order as the test_df"
      ],
      "metadata": {
        "id": "_zbxZ2reuBoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#Helps make printing numbers look better\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "train_df = pd.read_csv(\"Cars_train.csv\")\n",
        "\n",
        "test_df = pd.read_csv(\"Cars_test.csv\")\n",
        "test_df = test_df.drop('id', axis=1)"
      ],
      "metadata": {
        "id": "ZowcoCcBUnDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's have a quick look at the dataset"
      ],
      "metadata": {
        "id": "03yePzkXU4Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q1: Use some pandas built-in functions like head, describe, value_counts, etc. to take an initial look at train_df</b></h1>"
      ],
      "metadata": {
        "id": "X7jDgpnm36MU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7SsheSSMPe5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, we have price_category ranging from 0 to 4, each category meaning 0 to 100K, 100K to 200K, etc.\n",
        "\n",
        "The Price column is not needed since we're framing this as a classification problem. \n",
        "I only left it in case you're curious how much each car actually cost ðŸ’° (Be careful since the dataset was actually collected about 5 months ago so the majority of the prices you see in the dateset are a bit lower (okay, maybe much lower) than the current price\n",
        "\n",
        "<h2><b>Don't forget to run the next cell to drop the Price column before training</b><h2>\n",
        "\n"
      ],
      "metadata": {
        "id": "ZP4qcmbLVMiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop('Price', axis=1)"
      ],
      "metadata": {
        "id": "aKlPlJLqisij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q2: Use any visualization library you like to visualize some of the datasets attributes. Hint: One idea is to try plotting bar plots of categorical variables against the target variable like in the next cell. Other solutions are also welcome. </b></h1>"
      ],
      "metadata": {
        "id": "H0HZPbV_YGBf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4ak_qvD_vEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.groupby('price_category').Brand.value_counts().unstack().plot(kind='bar', figsize=(10,6))"
      ],
      "metadata": {
        "id": "VegZMlktW3Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try looking for trends and trying to ask and answer questions about the dataset,\n",
        "like are cars more likely to be more expensive the more recent they are?\n",
        "The next cell tries to answer that question.\n",
        "\n",
        "But always be careful not to jump into conclusions too early!"
      ],
      "metadata": {
        "id": "BnbD6DHpZPwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[train_df.Year > 2010].groupby('price_category').Year.value_counts().unstack().plot(kind='pie', figsize=(50,50), subplots=True)"
      ],
      "metadata": {
        "id": "8EOpUeZpZBoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Data for Machine Learning Algorithms"
      ],
      "metadata": {
        "id": "MFWOXWB5dtkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q3.1: Show the dtypes of each column in the dataset.</b></h1>"
      ],
      "metadata": {
        "id": "L8ch4s7PfAI2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jyi5feURe7oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q3.2: Use the 'select_dtypes' method in pandas to select columns which have the dtype 'object', assign that to a variable called cat_columns</b></h1>"
      ],
      "metadata": {
        "id": "uMNYG0XKdv1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: For questions requiring you to complete pieces of code, some comments will be explanatory and others will require you to write code.\n",
        "\n",
        "Comments that are part of a question are prefixed with TODO: to make it easier to find."
      ],
      "metadata": {
        "id": "t4e5pep-4TRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_columns = ['Brand', 'Model', 'Body', 'Color', 'Fuel', 'Kilometers', 'Engine','Transmission', 'Gov']\n",
        "#We'll use num_columns as provided here since it's not worth it to select_dtypes for it\n",
        "num_columns = ['Year'] \n",
        "\n",
        "cat_columns = #TODO: Now use select_dtypes here to get the same list as the one above"
      ],
      "metadata": {
        "id": "xLOdagEzeUFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell demonstrates how to:\n",
        "\n",
        "\n",
        "*   Transform categorical variable to one hot encoded variables\n",
        "*   Create a pandas dataframe from the transformed array\n",
        "\n",
        "\n",
        "But what if we want to join the created dataframe (which only contains the one hot representation of categorical variables) to the original dataframe?\n",
        "\n",
        "The next two questions illustrate this.\n",
        "\n",
        "First: Run the next cell\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hMAqiU7cf5fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "enc.fit(train_df[cat_columns])\n",
        "\n",
        "train_cat_one_hot = enc.transform(train_df[cat_columns])\n",
        "\n",
        "train_cat_one_hot_df = pd.DataFrame(train_cat_one_hot.toarray(), \n",
        "                                    columns=enc.get_feature_names_out(),\n",
        "                                    index=train_df.index)\n",
        "\n",
        "train_cat_one_hot_df"
      ],
      "metadata": {
        "id": "MOVljZkwgu1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q3.3: Now use the function `pd.concat` to concatenate `train_df` and`train_cat_one_hot_df`. Pay special attention to the axis argument of pd.`concat`  </b></h1>"
      ],
      "metadata": {
        "id": "H-WpSP5YgJiU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdzLcHoiguAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q3.4: Now drop cat_columns from the train_df since they are already one hot encoded </b></h1>"
      ],
      "metadata": {
        "id": "LjY3Za55gkU7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxJKgbOkgNHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q4: Use MinMaxScaler to transform num_columns to be in the range 0-1 </b></h1>"
      ],
      "metadata": {
        "id": "L2rkjizwhi_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "#TODO: fit the scaler on train[num_columns] first\n",
        "\n",
        "#TODO: Then set train[num_columns] to be the transformed output\n",
        "train_df[num_columns] = "
      ],
      "metadata": {
        "id": "li2k17BUhiV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q5: Put all of that into one preprocessing function! </b></h1>"
      ],
      "metadata": {
        "id": "lVNk37n4ePXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The string following the function declaration is called a docstring. \n",
        "\n",
        "It's a clean way to include documentation inside the code\n",
        "Data science usually doesn't have a lot of clean code but\n",
        "it's the right way to do things.\n",
        "\n",
        "You don't *need* to write docstrings for your functions in\n",
        "any of our tasks -this isn't the software engineering committee!-\n",
        "but it's just something to keep in mind for the future"
      ],
      "metadata": {
        "id": "mVZmRVNdZ5SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def preprocess(train_df, test_df=None):\n",
        "    \"\"\"Performs preprocessing on a Pandas DataFrame. \n",
        "    Optionally applies the same preprocessing steps\n",
        "    to transform a test dataframe if provided.\n",
        "\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    train_df: Pandas DataFrame\n",
        "        The dataframe to do preprocessing on. \n",
        "    test_df:  Pandas DataFrame\n",
        "        Optional. The test dataframe in case it exists.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    train_df Pandas DataFrame\n",
        "        The preprocessed training dataframe. \n",
        "    test_df [Pandas DataFrame or None]\n",
        "        The preprocessed test dataframe. \n",
        "        If no dataframe is provided then it's None.\n",
        "    \"\"\"\n",
        "\n",
        "    cat_columns = #TODO: Use the same answer as Q3.2\n",
        "    num_columns = #TODO: Use the as in Q3.2\n",
        "\n",
        "    enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    enc.fit(train_df[cat_columns])\n",
        "\n",
        "    train_cat_one_hot = enc.transform(train_df[cat_columns])\n",
        "\n",
        "    train_cat_one_hot_df = pd.DataFrame(train_cat_one_hot.toarray(), \n",
        "                                        columns=enc.get_feature_names_out(),\n",
        "                                        index=train_df.index)\n",
        "\n",
        "    train_df = #TODO: Same as in Q3.3\n",
        "    train_df = #TODO: Same as in Q3.4\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    #TODO: complete with the answer in Q4\n",
        "    \n",
        "\n",
        "\n",
        "    #This is to ensure the same preprocessing steps we did to train_df\n",
        "    #are applied to test_df\n",
        "    #It's the exact same code as above but with test_df instead of train_df\n",
        "    if test_df is not None:\n",
        "\n",
        "        test_cat_one_hot = enc.transform(test_df[cat_columns])\n",
        "\n",
        "        test_cat_one_hot_df = pd.DataFrame(test_cat_one_hot.toarray(), \n",
        "                                            columns=enc.get_feature_names_out(),\n",
        "                                            index=test_df.index)\n",
        "\n",
        "        test_df = #TODO: Same as Q3.3 and the above but test instead of train\n",
        "        test_df = #TODO: Same as Q3.4 and the above but test instead of train\n",
        "\n",
        "\n",
        "        \n",
        "        test_df[num_columns] = #TODO: Complete with scaler.transform\n",
        "        \n",
        "        #Note that we don't fit scaler or encoder to test_df. \n",
        "        #We only transform them\n",
        "\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "HzzRI1ZrWrYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After calling the function, the two dataframes should now be preprocessed."
      ],
      "metadata": {
        "id": "20P_lAgUx-Ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we need to load the data again because we edited it in the previous cells."
      ],
      "metadata": {
        "id": "S_e3CcBQ5vwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"Cars_train.csv\")\n",
        "train_df = train_df.drop('Price', axis=1)\n",
        "test_df = pd.read_csv(\"Cars_test.csv\")\n",
        "test_df = test_df.drop('id', axis=1)\n",
        "\n",
        "train_df, test_df = preprocess(train_df, test_df)\n"
      ],
      "metadata": {
        "id": "cfmz4Ah2cdTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Cross-Validation"
      ],
      "metadata": {
        "id": "PVfPRUKHiuZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q6: Create a variable X, that consists of train_df without the target variable, and another variable y consisting of just the target variable </b></h1>"
      ],
      "metadata": {
        "id": "T_jOyhP8yE41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = #TODO: fill in X\n",
        "y = #TODO: fill in y"
      ],
      "metadata": {
        "id": "-uE19ALBiHp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell demonstrates K-Fold Cross Validation \n",
        "*   We'll try doing hyperparameter tuning manually this time\n",
        "*   Try different models and try different combinations of hyperparameters\n",
        "*   You'll need to solve all of the next cell for the code to work\n"
      ],
      "metadata": {
        "id": "2K3ZFQXEjSqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q7: Fill in the missing pieces of code as indicated by the comments. Then, Try running the DummyClassifier and notice its performance. \n",
        "Now try different models and different hyperparameter combinations manually and see how far you can fly! \n",
        "\n",
        "(Don't worry it's not too far. Not because of you but because of the dataset Â¯\\\\_(ãƒ„)_/Â¯) </b></h1>"
      ],
      "metadata": {
        "id": "o5tRE85zyXI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "K = 5\n",
        "\n",
        "skf = StratifiedKFold(n_splits=K, random_state=0, shuffle=True)\n",
        "\n",
        "#We need to turn X and y into numpy array before inputting them to the model\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "fold_number = 1\n",
        "\n",
        "avg_accuracy = 0\n",
        "avg_precision = 0\n",
        "avg_recall = 0\n",
        "avg_f1 = 0\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "    #TODO: Try changing the type of the model and/or its hyperparameters manually!\n",
        "    clf = DummyClassifier(random_state=0)\n",
        "\n",
        "    #TODO: Fit the classifier on X_train and y_train\n",
        "    \n",
        "\n",
        "    #TODO: Save the classifier's predictions on X_test to preds\n",
        "    preds = \n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "\n",
        "    #The 'macro' helps generalize precision, recall, and f1 \n",
        "    #from binary to multiclass classification\n",
        "    #See: https://stephenallwright.com/micro-vs-macro-f1-score/\n",
        "    #For more information\n",
        "    precision = precision_score(y_test, preds, average='macro')\n",
        "    recall = #TODO: Do the same as precision_score for recall\n",
        "    f1 = #TODO: Do the same as precision_score for f1\n",
        "\n",
        "    #This prints metrics for each fold\n",
        "    print(f\"Accuracy for fold #{fold_number}: {accuracy}\")\n",
        "    print(f\"Precision for fold #{fold_number}: {precision}\")\n",
        "    print(f\"Recall for fold #{fold_number}: {recall}\")\n",
        "    print(f\"F1 Score for fold #{fold_number}: {f1}\\n\")\n",
        "\n",
        "    #This helps when calculating the average of metrics across folds\n",
        "    avg_accuracy += accuracy\n",
        "    avg_precision += precision\n",
        "    avg_recall += recall\n",
        "    avg_f1 += f1\n",
        "\n",
        "    fold_number += 1\n",
        "   \n",
        "\n",
        "print(f\"Average (Out of fold) Accuracy: {avg_accuracy/K}\")\n",
        "print(f\"Average (Out of fold) Precision: {avg_precision/K}\")\n",
        "print(f\"Average (Out of fold) Recall: {avg_recall/K}\")\n",
        "print(f\"Average (Out of fold) F1: {avg_f1/K}\")\n"
      ],
      "metadata": {
        "id": "1UyKiImUf7cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell displays the confusion matrix for the model using the very last values preds and y_test that were assigned in the loop.\n",
        "\n",
        "What do you notice about the model? What kind of classes does it confuse the most? Is the model overfitting? Try to think about these questions and let that guide you when choosing a model and doing hyperparameter tuning."
      ],
      "metadata": {
        "id": "VANssk0tzM-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#The normalize=\"all\" displays ratios instead of just frequencies\n",
        "#Multiplied by 100 for percentages\n",
        "#If you want to see the frequencies just remove normalize='all' and the * 100\n",
        "cm = confusion_matrix(y_test, preds, normalize=\"all\") * 100\n",
        "cmp = ConfusionMatrixDisplay(cm)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "cmp.plot(ax=ax)"
      ],
      "metadata": {
        "id": "T0jWLWGt_Vbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've used K-Fold Cross validation to choose a model, train the model you chose on all of the available data.\n",
        "\n",
        "<b>Remember that we only use K-Fold to get an estimate of each model's performance to be able to select a model, but when we've selected a model we want to train it on all available data, not just 4/5 on it in case of 5-Fold cross validation</b>"
      ],
      "metadata": {
        "id": "yNYkq2gZk4JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q8: For the final piece of the puzzle, fill in the next cell with the best model and hyperparameters you found using cross validation and train it on all the labeled data to be able to get predictions on the test set</b></h1>"
      ],
      "metadata": {
        "id": "0HvmA1r_-znb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = #TODO: Use the model and hyperparameters you found in Q7\n",
        "\n",
        "#TODO: Fit it using X and y (All of the training data)\n",
        "\n",
        "\n",
        "#Turn test_df into a numpy array and get the predictions\n",
        "test_df = test_df.to_numpy()\n",
        "preds = clf.predict(test_df)"
      ],
      "metadata": {
        "id": "BfnI3tKj_8yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Don't forget to submit the form and upload your submission to Kaggle:</h2></b>"
      ],
      "metadata": {
        "id": "LqYDs7eI-U7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Form link:\n",
        "\n",
        "https://forms.gle/8YYY5WAFhMQfrBJM9\n",
        "\n",
        "Kaggle link:\n",
        "\n",
        "https://www.kaggle.com/t/f21a20616b5f4e14b1dd03880225e9c7"
      ],
      "metadata": {
        "id": "JdTtNYRX-U72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "submission.price_category = preds\n",
        "\n",
        "submission.to_csv(\"cars_submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "J1V5ydAL-U72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Q9 (Optional) (Bonus): In case you're feeling adventrous, try running both GridSearchCV and RandomSearchCV for cross validation. (You can provide them the full X and y sets and they will handle the train/valid split).\n",
        " Did they get a better score than your hand-picked parameters? If so, by how much?</b></h1>"
      ],
      "metadata": {
        "id": "TJOdzV1d-2Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Aaaand we're done! Congratulations on making it this far! ðŸŽ‰ðŸŽ‰ðŸŽ‰</b></h1>"
      ],
      "metadata": {
        "id": "jK2EQAYq6uZu"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}